{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQzbSdfOjYwBfZKv+KZWXp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4qhnQoih9WmJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0cceac7e"},"source":["## Setup Environment and Libraries\n","\n","### Subtask:\n","Install necessary libraries such as MediaPipe, OpenCV, NumPy, etc., and configure the development environment.\n"]},{"cell_type":"code","metadata":{"id":"3e582f8c"},"source":["import sys\n","import subprocess\n","\n","def install_package(package):\n","    try:\n","        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n","        print(f\"Successfully installed {package}\")\n","    except subprocess.CalledProcessError as e:\n","        print(f\"Failed to install {package}: {e}\")\n","\n","install_package(\"mediapipe\")\n","install_package(\"opencv-python\")\n","install_package(\"numpy\")\n","install_package(\"pandas\")\n","install_package(\"matplotlib\")\n","install_package(\"seaborn\")\n","install_package(\"scipy\")\n","\n","print(\"All specified libraries have been installed.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b445bb32"},"source":["## Video Input Handling\n","\n","### Subtask:\n","Develop functionality to allow users to upload their 5-10 second workout video clips and load them for processing.\n"]},{"cell_type":"markdown","metadata":{"id":"4ef60e05"},"source":["## Video Input Handling\n","\n","### Subtask:\n","Develop functionality to allow users to upload their 5-10 second workout video clips and load them for processing.\n","\n","### Instructions to the user:\n","\n","1.  Run the next code cell to upload your video file. A file selection widget will appear.\n","2.  Select your workout video (preferably 5-10 seconds long) and upload it.\n","3.  After successful upload, the system will process the video and display its basic properties."]},{"cell_type":"code","metadata":{"id":"382442eb"},"source":["from google.colab import files\n","import cv2\n","import os\n","\n","# 1. Use files.upload() to create an upload widget\n","uploaded = files.upload()\n","\n","video_path = None\n","if uploaded:\n","    # Assuming only one file is uploaded for simplicity\n","    video_filename = list(uploaded.keys())[0]\n","    video_path = f\"/content/{video_filename}\"\n","    print(f\"Uploaded file: {video_filename}\")\n","\n","    # 3. Load the uploaded video file using cv2.VideoCapture()\n","    cap = cv2.VideoCapture(video_path)\n","\n","    # 4. Verify that the video has been successfully opened\n","    if not cap.isOpened():\n","        print(\"Error: Could not open video.\")\n","    else:\n","        # 5. Print basic video properties\n","        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","        fps = cap.get(cv2.CAP_PROP_FPS)\n","        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","        print(f\"\\nVideo Properties:\")\n","        print(f\"  Resolution: {frame_width}x{frame_height}\")\n","        print(f\"  FPS: {fps}\")\n","        print(f\"  Total Frames: {frame_count}\")\n","        print(f\"  Duration: {frame_count / fps:.2f} seconds\")\n","\n","        # Release the video capture object\n","        cap.release()\n","else:\n","    print(\"No file uploaded.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76b3e7a5"},"source":["## Pose Keypoint Detection\n","\n","### Subtask:\n","Implement a pose estimation model (e.g., MediaPipe Pose) to detect and extract 3D keypoints from each frame of the uploaded video.\n"]},{"cell_type":"code","metadata":{"id":"50e76b0a"},"source":["import mediapipe as mp\n","import cv2\n","import numpy as np\n","\n","# 1. Import mediapipe.solutions.pose\n","mp_pose = mp.solutions.pose\n","\n","# 2. Initialize the MediaPipe Pose model\n","# Set static_image_mode to False for video processing to track objects across frames\n","# Set model_complexity to 1 or 2 for higher accuracy if needed, 0 is fastest.\n","pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n","\n","# 3. Create an empty list to store detected keypoints\n","keypoints_data = []\n","\n","# Ensure video_path is available from previous step\n","if 'video_path' not in locals() or video_path is None:\n","    print(\"Error: video_path not found. Please upload a video first.\")\n","else:\n","    # 4. Re-open the uploaded video\n","    cap = cv2.VideoCapture(video_path)\n","\n","    if not cap.isOpened():\n","        print(\"Error: Could not re-open video for keypoint detection.\")\n","    else:\n","        frame_count_processed = 0\n","        print(\"Starting keypoint detection...\")\n","        while cap.isOpened():\n","            # 5. Loop through each frame of the video\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            # 6. Convert the frame from BGR to RGB\n","            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","            # 7. Process the RGB frame with MediaPipe Pose model\n","            results = pose.process(image_rgb)\n","\n","            # 8. If results.pose_landmarks are detected, append them to keypoints_data\n","            if results.pose_landmarks:\n","                # Store all landmarks for the current frame\n","                frame_landmarks = []\n","                for landmark in results.pose_landmarks.landmark:\n","                    frame_landmarks.append({\n","                        'x': landmark.x,\n","                        'y': landmark.y,\n","                        'z': landmark.z,\n","                        'visibility': landmark.visibility\n","                    })\n","                keypoints_data.append(frame_landmarks)\n","                frame_count_processed += 1\n","\n","        # 9. Release the video capture object\n","        cap.release()\n","        pose.close()\n","\n","        # 10. Print the total number of frames for which keypoints were detected\n","        print(f\"Keypoint detection complete. Detected keypoints for {len(keypoints_data)} frames.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d462b9f0"},"source":["import pandas as pd\n","\n","# Convert the list of keypoints for each frame into a DataFrame\n","# Each row represents a frame, and columns represent keypoint attributes (x, y, z, visibility) for each landmark\n","\n","if keypoints_data:\n","    # Flatten the list of lists into a list of dictionaries where each dict represents a landmark\n","    # and add a frame_id to link back to the original frame.\n","    flattened_data = []\n","    for frame_idx, frame_landmarks in enumerate(keypoints_data):\n","        for landmark_idx, landmark in enumerate(frame_landmarks):\n","            flattened_data.append({\n","                'frame_id': frame_idx,\n","                'landmark_id': landmark_idx,\n","                'x': landmark['x'],\n","                'y': landmark['y'],\n","                'z': landmark['z'],\n","                'visibility': landmark['visibility']\n","            })\n","\n","    keypoints_df = pd.DataFrame(flattened_data)\n","\n","    print(f\"Successfully converted {len(keypoints_data)} frames of keypoints into a DataFrame.\")\n","    print(f\"DataFrame shape: {keypoints_df.shape}\")\n","    print(\"\\nSample of keypoint data:\")\n","    display(keypoints_df.head())\n","else:\n","    print(\"No keypoints were detected or keypoints_data is empty.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"906a1cee"},"source":["## Keypoint Data Extraction and Smoothing\n","\n","### Subtask:\n","Extract time-series data for relevant keypoints (e.g., elbows, wrists, shoulders, hips) and apply smoothing techniques if necessary to reduce jitter.\n"]},{"cell_type":"code","metadata":{"id":"790bc827"},"source":["import pandas as pd\n","\n","# 1. Define a mapping from landmark_id to human-readable names for relevant keypoints\n","# Based on MediaPipe Pose documentation\n","keypoint_map = {\n","    11: 'left_shoulder',\n","    12: 'right_shoulder',\n","    13: 'left_elbow',\n","    14: 'right_elbow',\n","    15: 'left_wrist',\n","    16: 'right_wrist',\n","    23: 'left_hip',\n","    24: 'right_hip'\n","}\n","\n","# 2. Filter the keypoints_df DataFrame to include only the rows corresponding to these relevant keypoints\n","relevant_keypoints_df = keypoints_df[keypoints_df['landmark_id'].isin(keypoint_map.keys())].copy()\n","\n","# Add a 'keypoint_name' column to the filtered DataFrame\n","relevant_keypoints_df['keypoint_name'] = relevant_keypoints_df['landmark_id'].map(keypoint_map)\n","\n","# Prepare for pivoting: create a 'variable' column for x, y, z coordinates\n","# This will allow pivoting multiple columns simultaneously\n","\n","# Temporarily melt the x,y,z columns into rows for easier pivoting\n","melted_keypoints = relevant_keypoints_df.melt(id_vars=['frame_id', 'keypoint_name'],\n","                                                value_vars=['x', 'y', 'z'],\n","                                                var_name='coordinate_type',\n","                                                value_name='value')\n","\n","# Combine keypoint_name and coordinate_type to create new column names\n","melted_keypoints['new_column_name'] = melted_keypoints['keypoint_name'] + '_' + melted_keypoints['coordinate_type']\n","\n","# 3. Pivot the filtered and melted DataFrame\n","# Each row represents a frame, and columns represent the x, y, and z coordinates for each selected keypoint\n","pivoted_keypoints_df = melted_keypoints.pivot_table(index='frame_id', columns='new_column_name', values='value')\n","\n","# Reset index to make 'frame_id' a regular column if needed, but often better as index for time series\n","# pivoted_keypoints_df = pivoted_keypoints_df.reset_index()\n","\n","print(f\"Original keypoints_df shape: {keypoints_df.shape}\")\n","print(f\"Filtered relevant_keypoints_df shape: {relevant_keypoints_df.shape}\")\n","print(f\"Pivoted keypoints DataFrame shape: {pivoted_keypoints_df.shape}\")\n","print(\"\\nSample of pivoted keypoints data:\")\n","display(pivoted_keypoints_df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5c39520"},"source":["import pandas as pd\n","\n","# 4. Apply smoothing techniques\n","# A common approach is a rolling mean or a Savitzky-Golay filter.\n","# For rolling mean, a window size of 5-10 frames is often a good starting point for ~30 FPS videos.\n","# For Savitzky-Golay, a window length and polynomial order are needed.\n","\n","# Let's use a rolling mean for smoothing.\n","# We will use a window size that corresponds to approximately 0.2-0.3 seconds for a 30 FPS video\n","# window_size = int(fps * 0.25) # 0.25 seconds smoothing\n","# Using a fixed window size for now, can be made dynamic based on FPS\n","window_size = 5 # Example: 5 frames\n","\n","# Apply rolling mean to all coordinate columns\n","smoothed_keypoints_df = pivoted_keypoints_df.rolling(window=window_size, center=True, min_periods=1).mean()\n","\n","# Alternatively, using Savitzky-Golay filter for potentially better preservation of signal features\n","# Note: Savitzky-Golay requires non-NaN data, so we might need to handle NaNs introduced by rolling mean if applied after.\n","# For this example, applying directly to the pivoted_keypoints_df columns.\n","# window_length must be odd and greater than polyorder\n","\n","# from scipy.signal import savgol_filter # Removed this line due to ImportError\n","# savgol_window_length = 5 # Must be odd\n","# savgol_poly_order = 2\n","\n","# smoothed_keypoints_df_savgol = pivoted_keypoints_df.copy()\n","# for col in pivoted_keypoints_df.columns:\n","#     # Fill NaN values to apply savgol_filter, common strategy is forward fill or interpolate\n","#     # For simplicity, if a column has many NaNs, it might indicate bad detection for that keypoint/frame\n","#     # Here, we assume no NaNs in the middle, only at start/end due to min_periods if applied previously\n","#     smoothed_keypoints_df_savgol[col] = savgol_filter(pivoted_keypoints_df[col].fillna(method='ffill'), savgol_window_length, savgol_poly_order)\n","\n","print(f\"Smoothed keypoints DataFrame shape: {smoothed_keypoints_df.shape}\")\n","print(f\"Smoothing applied with a rolling mean window of {window_size} frames.\")\n","print(\"\\nSample of smoothed keypoints data:\")\n","display(smoothed_keypoints_df.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f41ca1e0"},"source":["## Define Exercise-Specific Form Rules\n","\n","### Subtask:\n","Develop rule-based logic for various exercises (e.g., bicep curl, lateral raise) including rules for angles (e.g., elbow angle), alignments (e.g., wrist-shoulder), and symmetry/posture (e.g., back angle).\n"]},{"cell_type":"code","metadata":{"id":"d44e3b63"},"source":["import numpy as np\n","import pandas as pd\n","\n","def calculate_angle(df, keypoint1_name, keypoint2_name, keypoint3_name):\n","    \"\"\"\n","    Calculates the 3D angle (in degrees) between three keypoints for each frame in the DataFrame.\n","\n","    Args:\n","        df (pd.DataFrame): DataFrame containing smoothed keypoint coordinates.\n","        keypoint1_name (str): Name of the first keypoint (e.g., 'right_shoulder').\n","        keypoint2_name (str): Name of the second (middle) keypoint (e.g., 'right_elbow').\n","        keypoint3_name (str): Name of the third keypoint (e.g., 'right_wrist').\n","\n","    Returns:\n","        pd.Series: A Series containing the angles in degrees for each frame.\n","    \"\"\"\n","    angles = []\n","    for index, row in df.iterrows():\n","        try:\n","            # Extract coordinates for the three keypoints\n","            p1 = np.array([row[f'{keypoint1_name}_x'], row[f'{keypoint1_name}_y'], row[f'{keypoint1_name}_z']])\n","            p2 = np.array([row[f'{keypoint2_name}_x'], row[f'{keypoint2_name}_y'], row[f'{keypoint2_name}_z']])\n","            p3 = np.array([row[f'{keypoint3_name}_x'], row[f'{keypoint3_name}_y'], row[f'{keypoint3_name}_z']])\n","\n","            # Calculate vectors\n","            v1 = p1 - p2\n","            v2 = p3 - p2\n","\n","            # Calculate the cosine of the angle using the dot product formula\n","            # Handle division by zero if a vector has zero magnitude\n","            dot_product = np.dot(v1, v2)\n","            magnitude_v1 = np.linalg.norm(v1)\n","            magnitude_v2 = np.linalg.norm(v2)\n","\n","            if magnitude_v1 == 0 or magnitude_v2 == 0:\n","                angle = np.nan # Undefined angle if a vector is zero\n","            else:\n","                cosine_angle = dot_product / (magnitude_v1 * magnitude_v2)\n","                # Clamp the value to the valid range [-1, 1] to avoid issues with floating point inaccuracies\n","                cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n","                angle = np.degrees(np.arccos(cosine_angle))\n","            angles.append(angle)\n","        except KeyError as e:\n","            print(f\"Missing keypoint coordinate: {e}. Skipping frame {index}.\")\n","            angles.append(np.nan)\n","        except Exception as e:\n","            print(f\"An error occurred during angle calculation for frame {index}: {e}. Skipping frame.\")\n","            angles.append(np.nan)\n","    return pd.Series(angles, index=df.index)\n","\n","print(\"Defined calculate_angle function.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"343cd260"},"source":["import pandas as pd\n","import numpy as np\n","\n","# Create a new DataFrame to store computed angles\n","angles_df = pd.DataFrame(index=smoothed_keypoints_df.index)\n","\n","# 1. Calculate Right Elbow Angle: (Right Shoulder - Right Elbow - Right Wrist)\n","angles_df['right_elbow_angle'] = calculate_angle(\n","    smoothed_keypoints_df, 'right_shoulder', 'right_elbow', 'right_wrist'\n",")\n","\n","# 2. Calculate Left Elbow Angle: (Left Shoulder - Left Elbow - Left Wrist)\n","angles_df['left_elbow_angle'] = calculate_angle(\n","    smoothed_keypoints_df, 'left_shoulder', 'left_elbow', 'left_wrist'\n",")\n","\n","# 3. Calculate Right Shoulder Angle: (Right Hip - Right Shoulder - Right Elbow)\n","angles_df['right_shoulder_angle'] = calculate_angle(\n","    smoothed_keypoints_df, 'right_hip', 'right_shoulder', 'right_elbow'\n",")\n","\n","# 4. Calculate Left Shoulder Angle: (Left Hip - Left Shoulder - Left Elbow)\n","angles_df['left_shoulder_angle'] = calculate_angle(\n","    smoothed_keypoints_df, 'left_hip', 'left_shoulder', 'left_elbow'\n",")\n","\n","# 5. Calculate Right Knee Angle: (Right Hip - Right Knee - Right Ankle)\n","# For bicep curls, knee angle might not be critical, but included for completeness in other exercises.\n","# Assuming keypoints for knee and ankle exist, if not, this will result in NaNs\n","# Keypoint IDs for knee and ankle: Right Hip (24), Right Knee (26), Right Ankle (28)\n","# Left Hip (23), Left Knee (25), Left Ankle (27)\n","# This assumes these keypoints were included in keypoint_map for pivoted_keypoints_df,\n","# but only specific ones were, so these will likely produce KeyError unless we update keypoint_map.\n","# Let's add them to the map for this step for future use if needed, but for now we focus on upper body for bicep curl\n","# To avoid error and stay focused on the bicep curl for now, I will comment out knee/ankle\n","\n","# Display the first few rows of the angles DataFrame\n","print(\"Calculated angles for relevant keypoints:\")\n","display(angles_df.head())\n","\n","print(f\"Angles DataFrame shape: {angles_df.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"03f0fad4"},"source":["bicep_curl_rules = {\n","    'start_position': {\n","        'right_elbow_angle': {'min': 160, 'max': 180, 'deviation_message': 'Right arm not fully extended at start.'},\n","        'left_elbow_angle': {'min': 160, 'max': 180, 'deviation_message': 'Left arm not fully extended at start.'},\n","        'right_shoulder_angle': {'min': 15, 'max': 45, 'deviation_message': 'Right shoulder not stable, arm swinging forward/backward.'},\n","        'left_shoulder_angle': {'min': 15, 'max': 45, 'deviation_message': 'Left shoulder not stable, arm swinging forward/backward.'}\n","    },\n","    'peak_contraction': {\n","        'right_elbow_angle': {'min': 30, 'max': 60, 'deviation_message': 'Right elbow not fully contracted.'},\n","        'left_elbow_angle': {'min': 30, 'max': 60, 'deviation_message': 'Left elbow not fully contracted.'}\n","    },\n","    'full_extension': {\n","        'right_elbow_angle': {'min': 160, 'max': 180, 'deviation_message': 'Right arm not fully extended at bottom.'},\n","        'left_elbow_angle': {'min': 160, 'max': 180, 'deviation_message': 'Left arm not fully extended at bottom.'}\n","    },\n","    'general_form': {\n","        'right_shoulder_angle': {'min': 10, 'max': 50, 'deviation_message': 'Right shoulder moving too much (swinging).'},\n","        'left_shoulder_angle': {'min': 10, 'max': 50, 'deviation_message': 'Left shoulder moving too much (swinging).'}\n","    }\n","}\n","\n","print(\"Defined bicep curl form rules.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c66b6025"},"source":["import pandas as pd\n","import numpy as np\n","\n","# 1. Initialize an empty list to store frame-wise feedback\n","frame_feedback = []\n","\n","def evaluate_frame_bicep_curl(frame_angles, bicep_curl_rules):\n","    \"\"\"\n","    Evaluates the form correctness for a single frame of a bicep curl exercise.\n","    Identifies the exercise phase and checks angles against general and phase-specific rules.\n","\n","    Args:\n","        frame_angles (pd.Series): A Series containing angle values for a single frame.\n","        bicep_curl_rules (dict): A dictionary defining the rules for bicep curl form.\n","\n","    Returns:\n","        list: A list of deviation messages for the current frame.\n","    \"\"\"\n","    deviations = []\n","\n","    right_elbow_angle = frame_angles.get('right_elbow_angle')\n","    left_elbow_angle = frame_angles.get('left_elbow_angle')\n","\n","    # Determine the current exercise phase based on elbow angles\n","    phase_rules_to_check = {}\n","    identified_phase = None\n","\n","    if pd.notna(right_elbow_angle) and pd.notna(left_elbow_angle):\n","        # Check for Peak Contraction phase\n","        peak_right_min = bicep_curl_rules['peak_contraction']['right_elbow_angle']['min']\n","        peak_right_max = bicep_curl_rules['peak_contraction']['right_elbow_angle']['max']\n","        peak_left_min = bicep_curl_rules['peak_contraction']['left_elbow_angle']['min']\n","        peak_left_max = bicep_curl_rules['peak_contraction']['left_elbow_angle']['max']\n","\n","        if (peak_right_min <= right_elbow_angle <= peak_right_max) and \\\n","           (peak_left_min <= left_elbow_angle <= peak_left_max):\n","            phase_rules_to_check = bicep_curl_rules['peak_contraction']\n","            identified_phase = 'peak_contraction'\n","        else:\n","            # If not peak contraction, check for extended positions (start or full extension)\n","            # Since rules for start_position and full_extension are identical for elbow angles, we can check against one.\n","            extended_right_min = bicep_curl_rules['start_position']['right_elbow_angle']['min']\n","            extended_right_max = bicep_curl_rules['start_position']['right_elbow_angle']['max']\n","            extended_left_min = bicep_curl_rules['start_position']['left_elbow_angle']['min']\n","            extended_left_max = bicep_curl_rules['start_position']['left_elbow_angle']['max']\n","\n","            if (extended_right_min <= right_elbow_angle <= extended_right_max) and \\\n","               (extended_left_min <= left_elbow_angle <= extended_left_max):\n","                phase_rules_to_check = bicep_curl_rules['start_position'] # Apply start/full extension rules\n","                identified_phase = 'extended_position' # Could be start or full extension\n","\n","    # Check 'general_form' rules\n","    for angle_name, rule_limits in bicep_curl_rules['general_form'].items():\n","        angle_value = frame_angles.get(angle_name)\n","        if pd.notna(angle_value):\n","            if not (rule_limits['min'] <= angle_value <= rule_limits['max']):\n","                deviations.append(f\"{angle_name.replace('_', ' ').title()}: {rule_limits['deviation_message']}\")\n","\n","    # Check phase-specific rules if a phase was identified\n","    for angle_name, rule_limits in phase_rules_to_check.items():\n","        angle_value = frame_angles.get(angle_name)\n","        if pd.notna(angle_value):\n","            if not (rule_limits['min'] <= angle_value <= rule_limits['max']):\n","                # Avoid duplicate messages if general form already caught it\n","                deviation_msg = f\"{angle_name.replace('_', ' ').title()}: {rule_limits['deviation_message']}\"\n","                if deviation_msg not in deviations:\n","                    deviations.append(deviation_msg)\n","\n","    return deviations\n","\n","# 3. Iterate through each row (frame) of the angles_df DataFrame\n","for frame_id, frame_angles_series in angles_df.iterrows():\n","    deviations = evaluate_frame_bicep_curl(frame_angles_series, bicep_curl_rules)\n","    frame_feedback.append({'frame_id': frame_id, 'deviations': deviations})\n","\n","# 4. Print the first 10 entries of the frame_feedback list\n","print(\"Sample of frame-wise feedback (first 10 entries):\")\n","for entry in frame_feedback[:10]:\n","    print(f\"Frame {entry['frame_id']}: {entry['deviations']}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"97797ff8"},"source":["## Generate Visual Feedback Video\n","\n","### Subtask:\n","Create a new video with overlays on the original user video, showing detected keypoints, relevant angles/lines, and real-time textual feedback on form correctness (e.g., 'Elbow too low!', 'Good form').\n"]},{"cell_type":"code","metadata":{"id":"baf20d3b"},"source":["import cv2\n","import numpy as np\n","import mediapipe as mp\n","from IPython.display import Video, display\n","\n","# 1. Re-open the original user-uploaded video\n","cap = cv2.VideoCapture(video_path)\n","\n","# Ensure video properties are available (from previous steps)\n","if 'fps' not in locals() or 'frame_width' not in locals() or 'frame_height' not in locals():\n","    # Fallback to re-calculating if not found (should be present from previous upload step)\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    if not cap.isOpened():\n","        print(\"Error: Could not open video to re-calculate properties.\")\n","\n","# 2. Initialize MediaPipe drawing utilities (we won't use draw_landmarks directly, but we need POSE_CONNECTIONS)\n","mp_drawing = mp.solutions.drawing_utils\n","mp_pose = mp.solutions.pose\n","\n","# 3. Create a cv2.VideoWriter object to save the output video\n","output_video_path = '/content/workout_feedback_video.mp4'\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec for .mp4 files\n","out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n","\n","print(f\"Generating feedback video... (Output: {output_video_path})\")\n","\n","frame_idx = 0\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    annotated_frame = frame.copy()\n","\n","    # Define a helper function to get pixel coordinates for any landmark\n","    def get_pixel_coords_all_landmarks(landmark_data, frame_width, frame_height):\n","        lm_dict = {}\n","        # landmark_data is a list of dictionaries for the current frame\n","        for idx, lm in enumerate(landmark_data):\n","            if lm['visibility'] > 0.5: # Only consider visible landmarks\n","                lm_dict[idx] = (int(lm['x'] * frame_width), int(lm['y'] * frame_height))\n","        return lm_dict\n","\n","    # 4a. Manually draw landmarks and connections on the frame\n","    if frame_idx < len(keypoints_data):\n","        current_frame_keypoints_raw = keypoints_data[frame_idx]\n","        all_landmarks_pixel = get_pixel_coords_all_landmarks(current_frame_keypoints_raw, frame_width, frame_height)\n","\n","        # Draw connections\n","        for connection in mp_pose.POSE_CONNECTIONS:\n","            start_idx, end_idx = connection\n","            if start_idx in all_landmarks_pixel and end_idx in all_landmarks_pixel:\n","                cv2.line(annotated_frame, all_landmarks_pixel[start_idx], all_landmarks_pixel[end_idx], (0, 0, 255), 2) # Red connections\n","\n","        # Draw landmarks as circles\n","        for idx, (x_px, y_px) in all_landmarks_pixel.items():\n","            cv2.circle(annotated_frame, (x_px, y_px), 3, (0, 255, 0), -1) # Green circles\n","\n","    # 4b. Draw lines representing angles and add angle values as text\n","    if frame_idx < len(smoothed_keypoints_df):\n","        current_smoothed_keypoints = smoothed_keypoints_df.iloc[frame_idx]\n","        # Retrieve angles for the current frame\n","        current_angles = angles_df.iloc[frame_idx]\n","\n","        # Need pixel coordinates for drawing, using the previously defined get_pixel_coords for relevant keypoints\n","        def get_pixel_coords_relevant(row, kp_name, frame_width, frame_height):\n","            # Ensure kp_name exists in the row (e.g., 'right_shoulder_x')\n","            if f'{kp_name}_x' in row and f'{kp_name}_y' in row:\n","                return (int(row[f'{kp_name}_x'] * frame_width),\n","                        int(row[f'{kp_name}_y'] * frame_height))\n","            return None\n","\n","\n","        # Only draw if angle is not NaN\n","        if pd.notna(current_angles.get('right_elbow_angle')):\n","            p_r_shoulder = get_pixel_coords_relevant(current_smoothed_keypoints, 'right_shoulder', frame_width, frame_height)\n","            p_r_elbow = get_pixel_coords_relevant(current_smoothed_keypoints, 'right_elbow', frame_width, frame_height)\n","            p_r_wrist = get_pixel_coords_relevant(current_smoothed_keypoints, 'right_wrist', frame_width, frame_height)\n","\n","            if all(p is not None for p in [p_r_shoulder, p_r_elbow, p_r_wrist]):\n","                # Draw lines forming the angle\n","                cv2.line(annotated_frame, p_r_shoulder, p_r_elbow, (255, 255, 0), 2)\n","                cv2.line(annotated_frame, p_r_elbow, p_r_wrist, (255, 255, 0), 2)\n","\n","                # Put angle text\n","                angle_text = f\"R-Elbow: {current_angles['right_elbow_angle']:.1f}\"\n","                cv2.putText(annotated_frame, angle_text, (p_r_elbow[0] + 10, p_r_elbow[1] - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1, cv2.LINE_AA)\n","\n","        if pd.notna(current_angles.get('left_elbow_angle')):\n","            p_l_shoulder = get_pixel_coords_relevant(current_smoothed_keypoints, 'left_shoulder', frame_width, frame_height)\n","            p_l_elbow = get_pixel_coords_relevant(current_smoothed_keypoints, 'left_elbow', frame_width, frame_height)\n","            p_l_wrist = get_pixel_coords_relevant(current_smoothed_keypoints, 'left_wrist', frame_width, frame_height)\n","\n","            if all(p is not None for p in [p_l_shoulder, p_l_elbow, p_l_wrist]):\n","                cv2.line(annotated_frame, p_l_shoulder, p_l_elbow, (0, 255, 255), 2)\n","                cv2.line(annotated_frame, p_l_elbow, p_l_wrist, (0, 255, 255), 2)\n","\n","                angle_text = f\"L-Elbow: {current_angles['left_elbow_angle']:.1f}\"\n","                cv2.putText(annotated_frame, angle_text, (p_l_elbow[0] + 10, p_l_elbow[1] - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1, cv2.LINE_AA)\n","\n","        if pd.notna(current_angles.get('right_shoulder_angle')):\n","            p_r_hip = get_pixel_coords_relevant(current_smoothed_keypoints, 'right_hip', frame_width, frame_height)\n","            p_r_shoulder = get_pixel_coords_relevant(current_smoothed_keypoints, 'right_shoulder', frame_width, frame_height)\n","            p_r_elbow = get_pixel_coords_relevant(current_smoothed_keypoints, 'right_elbow', frame_width, frame_height)\n","\n","            if all(p is not None for p in [p_r_hip, p_r_shoulder, p_r_elbow]):\n","                cv2.line(annotated_frame, p_r_hip, p_r_shoulder, (255, 0, 255), 2)\n","                cv2.line(annotated_frame, p_r_shoulder, p_r_elbow, (255, 0, 255), 2)\n","\n","                angle_text = f\"R-Shoulder: {current_angles['right_shoulder_angle']:.1f}\"\n","                cv2.putText(annotated_frame, angle_text, (p_r_shoulder[0] + 10, p_r_shoulder[1] - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1, cv2.LINE_AA)\n","\n","        if pd.notna(current_angles.get('left_shoulder_angle')):\n","            p_l_hip = get_pixel_coords_relevant(current_smoothed_keypoints, 'left_hip', frame_width, frame_height)\n","            p_l_shoulder = get_pixel_coords_relevant(current_smoothed_keypoints, 'left_shoulder', frame_width, frame_height)\n","            p_l_elbow = get_pixel_coords_relevant(current_smoothed_keypoints, 'left_elbow', frame_width, frame_height)\n","\n","            if all(p is not None for p in [p_l_hip, p_l_shoulder, p_l_elbow]):\n","                cv2.line(annotated_frame, p_l_hip, p_l_shoulder, (0, 165, 255), 2)\n","                cv2.line(annotated_frame, p_l_shoulder, p_l_elbow, (0, 165, 255), 2)\n","\n","                angle_text = f\"L-Shoulder: {current_angles['left_shoulder_angle']:.1f}\"\n","                cv2.putText(annotated_frame, angle_text, (p_l_shoulder[0] + 10, p_l_shoulder[1] - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 1, cv2.LINE_AA)\n","\n","\n","    # 4c. Retrieve and display textual feedback messages\n","    feedback_messages = frame_feedback[frame_idx]['deviations'] if frame_idx < len(frame_feedback) else []\n","    y_offset = 30 # Initial vertical position for text\n","    for msg in feedback_messages:\n","        cv2.putText(annotated_frame, msg, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)\n","        y_offset += 30\n","\n","    # If no deviations, display 'Good Form!' or similar\n","    if not feedback_messages and frame_idx < len(smoothed_keypoints_df): # Only if keypoints were detected for the frame\n","         cv2.putText(annotated_frame, 'Good Form!', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n","\n","    # 4d. Write the modified frame to the cv2.VideoWriter object\n","    out.write(annotated_frame)\n","    frame_idx += 1\n","\n","# 5. Release the video capture and video writer objects\n","cap.release()\n","out.release()\n","\n","print(f\"Feedback video generated successfully: {output_video_path}\")\n","\n","# 6. Optionally, display the generated video within the Colab notebook\n","print(\"Displaying generated video:\")\n","display(Video(output_video_path, embed=True, width=600))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"47df7211"},"source":["from collections import defaultdict\n","\n","# 1. Aggregate deviations from the frame_feedback list\n","# 2. Count occurrences and calculate percentages\n","\n","all_deviations_count = defaultdict(int)\n","frame_count_with_deviations = defaultdict(int)\n","total_frames = len(frame_feedback)\n","\n","for entry in frame_feedback:\n","    for deviation_msg in entry['deviations']:\n","        all_deviations_count[deviation_msg] += 1\n","    # Count how many frames each unique deviation appeared in (only once per frame)\n","    for unique_deviation in set(entry['deviations']):\n","        frame_count_with_deviations[unique_deviation] += 1\n","\n","# Prepare summary data\n","deviation_summary = []\n","for msg, total_occurrences in all_deviations_count.items():\n","    # Calculate percentage based on frames where it occurred, not total occurrences\n","    frames_with_this_deviation = frame_count_with_deviations[msg]\n","    percentage = (frames_with_this_deviation / total_frames) * 100\n","    deviation_summary.append({\n","        'deviation': msg,\n","        'total_occurrences': total_occurrences,\n","        'frames_affected': frames_with_this_deviation,\n","        'percentage_of_frames': percentage\n","    })\n","\n","# Sort by percentage descending\n","deviation_summary.sort(key=lambda x: x['percentage_of_frames'], reverse=True)\n","\n","print(\"Deviation Summary:\")\n","for item in deviation_summary:\n","    print(f\"- {item['deviation']}: Occurred in {item['frames_affected']}/{total_frames} frames ({item['percentage_of_frames']:.2f}%)\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38361213"},"source":["import datetime\n","\n","# 3. Formulate actionable advice for improvement\n","# This can be expanded with more specific advice for various exercises and deviation types.\n","advice_map = {\n","    'Right arm not fully extended at start.': 'Ensure your right arm is fully extended at the bottom of the curl to maximize range of motion and engage the bicep fully.',\n","    'Left arm not fully extended at start.': 'Ensure your left arm is fully extended at the bottom of the curl to maximize range of motion and engage the bicep fully.',\n","    'Right shoulder not stable, arm swinging forward/backward.': 'Keep your right shoulder stable and tucked back. Avoid using momentum from your shoulder; focus on isolating the bicep.',\n","    'Left shoulder not stable, arm swinging forward/backward.': 'Keep your left shoulder stable and tucked back. Avoid using momentum from your shoulder; focus on isolating the bicep.',\n","    'Right elbow not fully contracted.': 'Bring your right hand up higher to achieve a full bicep contraction. Focus on squeezing the bicep at the top of the movement.',\n","    'Left elbow not fully contracted.': 'Bring your left hand up higher to achieve a full bicep contraction. Focus on squeezing the bicep at the top of the movement.',\n","    'Right arm not fully extended at bottom.': 'Ensure your right arm extends completely at the bottom of the movement. This ensures a full range of motion and proper muscle engagement.',\n","    'Left arm not fully extended at bottom.': 'Ensure your left arm extends completely at the bottom of the movement. This ensures a full range of motion and proper muscle engagement.',\n","    'Right shoulder moving too much (swinging).': 'Minimize right shoulder movement. Keep your elbows close to your body and focus on curling with your biceps, not swinging with your shoulders.',\n","    'Left shoulder moving too much (swinging).': 'Minimize left shoulder movement. Keep your elbows close to your body and focus on curling with your biceps, not swinging with your shoulders.'\n","}\n","\n","# 4. Structure the information into a readable textual report\n","report_content = []\n","\n","report_content.append(\"Fitness Form Analysis Report\")\n","report_content.append(\"Date: \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n","report_content.append(\"---------------------------------------------------\")\n","report_content.append(\"\\nOverall Performance Summary:\")\n","if not deviation_summary:\n","    report_content.append(\"  Great job! No significant deviations were detected in your workout.\")\n","else:\n","    report_content.append(\"  Several deviations were observed during your workout. Review the specific issues and advice below to improve your form.\")\n","\n","report_content.append(\"\\nSpecific Issues Detected:\")\n","if not deviation_summary:\n","    report_content.append(\"  None.\")\n","else:\n","    for item in deviation_summary:\n","        report_content.append(f\"  - {item['deviation']} (Observed in {item['percentage_of_frames']:.2f}% of frames)\")\n","\n","report_content.append(\"\\nPersonalized Corrective Advice:\")\n","if not deviation_summary:\n","    report_content.append(\"  Keep up the good work!\")\n","else:\n","    for item in deviation_summary:\n","        deviation_message = item['deviation'].split(': ')[-1] # Extract just the deviation message part\n","        advice = advice_map.get(deviation_message, \"No specific advice available for this deviation. Consult a trainer.\")\n","        report_content.append(f\"  - For '{deviation_message}': {advice}\")\n","\n","report_content.append(\"\\n---------------------------------------------------\")\n","report_content.append(\"Recommendations:\")\n","report_content.append(\"  - Review the visual feedback video for frame-by-frame guidance.\")\n","report_content.append(\"  - Focus on slow, controlled movements to maintain proper form throughout the exercise.\")\n","report_content.append(\"  - Consider using lighter weights if form is consistently breaking down.\")\n","report_content.append(\"  - Practice in front of a mirror to self-correct in real-time.\")\n","\n","final_report_text = \"\\n\".join(report_content)\n","\n","# 5. Save the generated report to a text file\n","report_filename = \"workout_report.txt\"\n","with open(report_filename, \"w\") as f:\n","    f.write(final_report_text)\n","\n","print(f\"Detailed textual report saved to {report_filename}\")\n","print(\"\\n--- Report Content Preview ---\")\n","print(final_report_text)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9c3754c2"},"source":["import os\n","\n","# 1. Define the output_video_path variable\n","output_video_path = '/content/workout_feedback_video.mp4'\n","\n","# 2. Check if the file exists\n","if os.path.exists(output_video_path):\n","    # 3. Get file size if it exists\n","    file_size_bytes = os.path.getsize(output_video_path)\n","    file_size_mb = file_size_bytes / (1024 * 1024) # Convert bytes to MB\n","    print(f\"The feedback video '{output_video_path}' exists.\")\n","    print(f\"File size: {file_size_mb:.2f} MB\")\n","else:\n","    print(f\"Error: The feedback video '{output_video_path}' does not exist.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e4e9a44c"},"source":["from google.colab import files\n","\n","# Assuming output_video_path is already defined from the previous cell\n","# If not, uncomment and define it:\n","# output_video_path = '/content/workout_feedback_video.mp4'\n","\n","if os.path.exists(output_video_path):\n","    print(f\"\\nGenerating download link for '{output_video_path}'...\")\n","    files.download(output_video_path)\n","else:\n","    print(f\"Error: Cannot generate download link. The file '{output_video_path}' does not exist.\")"],"execution_count":null,"outputs":[]}]}